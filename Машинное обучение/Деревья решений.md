### Метод энтропии  
Энтропия - это мера определённости (в случае с деревьями решений). Абсолютная неопределённость и полная определённость соответственно 1 и 0  
$$E=-\sum_{i=1}^{n} p_i\cdot\log_2(p_i)$$  
В формуле выше n - это количество вариантов результата, а p - вероятность каждого из них. Например, данные, где 4 котика и 6 собачек:  
$$E=-\frac{4}{10}\cdot\log_2\frac{4}{10}-\frac{6}{10}\cdot\log_2\frac{6}{10}=0.971$$  
Суть метода состоит в том, что необходимо на каждую *"фичу"* (предиктор, переменная, столбик в data frame) последовательно вычислить их энтропии, разбить по этой фиче данные на *сплит*, в котором далее вычислять энтропии и разбивать данные на более мелкие, пока не будет достигнута нулевая энтропия на каждой ветке  
![Pasted image 20221124161328.png|450](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124161328.png?raw=true)  
На каждом уровне вычисляется вычисляются энтропия для всех фичей и применяется самая маленькая  
Также есть понятие *Information Gain* - мера снижения неопределённости между сплитами. Нужно для оценки разбиения  
$$IG=E(Y)-E(Y/X)$$  
В формуле выше $E(Y)$ - это изначальная энтропия, а $E(Y/X)$ - энтропия при разбиении по фиче $X$  
  
### Кроссвалидация  
Глубина такого дерева может быть очень большой, что приведёт к переобучению модели. Чтобы избежать переобучения можно указать точную максимальную длину дерева. Для нахождения оптимальной длины можно разбить данные на *тестовые* и *тренировочные*. Вторыми модель тренировать, а первых она не видит до начала тестирования и на тестировании проверять корректность. Если учить модель 100 раз, чтобы глубина дерева была от 1 до 100, можно получить такой график:  
![Pasted image 20221124203249.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124203249.png?raw=true)  
Видно, что *score* наилучший при глубине дерева примерно 4. Но такой тест **неправильный** и приводит к переобучению модели. Дело в том, что тренировочные данные могли идеально подойти конкретно под глубину дерева равную 4, а не глубина 4 под данные. Для этого используется *кроссвалидация*.   
![Pasted image 20221124203714.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124203714.png?raw=true)  
На рисунке выше описана схема работы. Тренировочные данные пилятся ещё на, допустим, 5 кусков. Тогда на каждой из 5 итераций каждый кусок вынимается и модель обучается на остальных 4-х. Тот исключённый кусок является тестовым и на нём проверяется точность модели. Получается пять *точностей*, среднее из которых будет более корректным значением для оценки конкретной глубины дерева. Исправленный график ниже:  
![Pasted image 20221124204523.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124204523.png?raw=true)  
Из него видно, что глубина 4 является не самой лучшей по усреднённым тестам